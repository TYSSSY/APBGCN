{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from data.dataset import SkeletonDataset\n",
    "from torch_geometric.data import DataLoader\n",
    "from models.net import DualGraphTransformer\n",
    "from torch.autograd import Variable\n",
    "from einops import rearrange\n",
    "from args import make_args\n",
    "from optimizer import get_std_opt\n",
    "from torch_scatter import scatter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset= SkeletonDataset(root=\"/home/project/gcn/Apb-gcn/NTU-RGB+D\", name='cv_val', benchmark='cv', sample = 'val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset.labels = train_dataset.labels.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset.data, batch_size = 4)\n",
    "#val_loader = DataLoader(val_dataset, batch_size = 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DualGraphTransformer(in_channels = 7, hidden_channels = 16, out_channels = 16, num_layers = 4, num_heads = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(torch.device('cuda:0'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([379, 25, 7])\n",
      "tensor(4.1446, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([607, 25, 7])\n",
      "tensor(4.1048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([407, 25, 7])\n",
      "tensor(4.0200, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([678, 25, 7])\n",
      "tensor(4.1118, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([401, 25, 7])\n",
      "tensor(4.1836, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([492, 25, 7])\n",
      "tensor(4.1464, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([374, 25, 7])\n",
      "tensor(4.0969, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([333, 25, 7])\n",
      "tensor(4.1243, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([365, 25, 7])\n",
      "tensor(4.1098, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([339, 25, 7])\n",
      "tensor(4.2247, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([424, 25, 7])\n",
      "tensor(4.2079, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([475, 25, 7])\n",
      "tensor(4.1067, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([323, 25, 7])\n",
      "tensor(4.1072, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([431, 25, 7])\n",
      "tensor(4.1136, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([294, 25, 7])\n",
      "tensor(4.1277, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([375, 25, 7])\n",
      "tensor(4.1081, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([418, 25, 7])\n",
      "tensor(4.1048, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([289, 25, 7])\n",
      "tensor(4.1113, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([282, 25, 7])\n",
      "tensor(4.1070, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([459, 25, 7])\n",
      "tensor(4.1043, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([392, 25, 7])\n",
      "tensor(4.0943, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([499, 25, 7])\n",
      "tensor([[[ 0.2853, -0.4639,  3.9641,  ...,  1.5708,  1.5708,  4.0014],\n",
      "         [ 0.2694, -0.1564,  3.9471,  ...,  1.5708,  1.5708,  3.9594],\n",
      "         [ 0.2538,  0.1467,  3.9176,  ...,  1.5708,  1.5708,  3.9285],\n",
      "         ...,\n",
      "         [ 0.1157, -0.5402,  3.7323,  ...,  1.5708,  1.5708,  3.7730],\n",
      "         [ 0.4648, -0.6103,  3.9954,  ...,  1.5708,  1.5708,  4.0683],\n",
      "         [ 0.4429, -0.5155,  3.9560,  ...,  1.5708,  1.5708,  4.0140]],\n",
      "\n",
      "        [[ 0.2863, -0.4636,  3.9642,  ...,  1.5706,  1.5707,  4.0015],\n",
      "         [ 0.2703, -0.1558,  3.9473,  ...,  1.5706,  1.5706,  3.9596],\n",
      "         [ 0.2545,  0.1476,  3.9177,  ...,  1.5706,  1.5706,  3.9288],\n",
      "         ...,\n",
      "         [ 0.1318, -0.5326,  3.7705,  ...,  1.5666,  1.5688,  3.8102],\n",
      "         [ 0.4685, -0.5973,  3.9809,  ...,  1.5699,  1.5676,  4.0527],\n",
      "         [ 0.4433, -0.5163,  3.9552,  ...,  1.5707,  1.5710,  4.0133]],\n",
      "\n",
      "        [[ 0.2872, -0.4635,  3.9646,  ...,  1.5706,  1.5708,  4.0019],\n",
      "         [ 0.2717, -0.1554,  3.9482,  ...,  1.5704,  1.5707,  3.9606],\n",
      "         [ 0.2562,  0.1482,  3.9192,  ...,  1.5704,  1.5706,  3.9304],\n",
      "         ...,\n",
      "         [ 0.1306, -0.5362,  3.7631,  ...,  1.5711,  1.5717,  3.8033],\n",
      "         [ 0.4616, -0.6079,  3.9868,  ...,  1.5725,  1.5734,  4.0592],\n",
      "         [ 0.4441, -0.5408,  3.9632,  ...,  1.5706,  1.5769,  4.0246]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         ...,\n",
      "         [-0.3781, -0.0695,  0.5666,  ...,     nan,  0.6327,  0.6847],\n",
      "         [-0.3854, -0.0917,  0.5866,  ...,     nan,  0.5366,  0.7079],\n",
      "         [-0.3842, -0.0685,  0.5622,  ...,     nan,  0.4771,  0.6844]],\n",
      "\n",
      "        [[-0.4797, -0.1256,  0.7517,  ...,  2.1326,  1.7108,  0.9005],\n",
      "         [-0.4660, -0.1220,  0.7301,  ...,  2.1326,  1.7108,  0.8747],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         ...,\n",
      "         [-0.3985, -0.0503,  0.5543,  ...,  1.6006,  1.5427,  0.6846],\n",
      "         [-2.4598, -0.9662,  3.7300,  ...,  2.0418,  1.7633,  4.5713],\n",
      "         [-2.4586, -0.9419,  3.7058,  ...,  2.0447,  1.7641,  4.5458]],\n",
      "\n",
      "        [[ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         [ 0.0000,  0.0000,  0.0000,  ...,     nan,     nan,  0.0000],\n",
      "         ...,\n",
      "         [-0.2104, -0.0480,  0.3272,  ...,  1.0701,  1.5650,  0.3919],\n",
      "         [-0.2202, -0.0676,  0.3459,  ...,     nan,     nan,  0.4156],\n",
      "         [-0.2192, -0.0440,  0.3214,  ...,     nan,     nan,  0.3915]]],\n",
      "       device='cuda:0')\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([317, 25, 7])\n",
      "tensor([[[-2.2289e-02, -1.1128e-01,  2.8143e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.8166e+00],\n",
      "         [ 6.1807e-04,  1.8407e-01,  2.7300e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.7362e+00],\n",
      "         [ 2.4627e-02,  4.7077e-01,  2.6321e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.6740e+00],\n",
      "         ...,\n",
      "         [-1.7112e-01, -1.2274e-01,  2.7814e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.7894e+00],\n",
      "         [ 1.3302e-01, -2.4476e-01,  2.6682e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.6827e+00],\n",
      "         [ 1.1675e-01, -1.7611e-01,  2.6591e+00,  ...,  1.5708e+00,\n",
      "           1.5708e+00,  2.6675e+00]],\n",
      "\n",
      "        [[ 5.0927e-01, -2.1400e-01,  2.6310e+00,  ...,  1.3718e+00,\n",
      "           1.6090e+00,  2.6884e+00],\n",
      "         [ 4.9394e-01,  4.8316e-02,  2.5748e+00,  ...,  1.3815e+00,\n",
      "           1.6226e+00,  2.6222e+00],\n",
      "         [ 4.7771e-01,  3.0348e-01,  2.5074e+00,  ...,  1.3936e+00,\n",
      "           1.6359e+00,  2.5705e+00],\n",
      "         ...,\n",
      "         [ 2.9395e-01, -2.9762e-01,  2.5486e+00,  ...,  1.3897e+00,\n",
      "           1.6386e+00,  2.5827e+00],\n",
      "         [ 6.7288e-01, -3.4172e-01,  2.5769e+00,  ...,  1.3684e+00,\n",
      "           1.6069e+00,  2.6851e+00],\n",
      "         [ 6.9315e-01, -2.9672e-01,  2.5471e+00,  ...,  1.3521e+00,\n",
      "           1.6162e+00,  2.6564e+00]],\n",
      "\n",
      "        [[-2.5578e-02, -1.1104e-01,  2.8174e+00,  ...,  1.7616e+00,\n",
      "           1.5343e+00,  2.8197e+00],\n",
      "         [ 1.7170e-04,  1.8366e-01,  2.7301e+00,  ...,  1.7522e+00,\n",
      "           1.5213e+00,  2.7362e+00],\n",
      "         [ 2.4862e-02,  4.6926e-01,  2.6305e+00,  ...,  1.7411e+00,\n",
      "           1.5087e+00,  2.6721e+00],\n",
      "         ...,\n",
      "         [-1.7801e-01, -1.2571e-01,  2.7973e+00,  ...,  1.7398e+00,\n",
      "           1.5095e+00,  2.8058e+00],\n",
      "         [ 1.1872e-01, -2.4574e-01,  2.6668e+00,  ...,  1.7790e+00,\n",
      "           1.5350e+00,  2.6807e+00],\n",
      "         [ 1.0447e-01, -1.8622e-01,  2.6522e+00,  ...,  1.7939e+00,\n",
      "           1.5293e+00,  2.6607e+00]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[ 5.1587e-01,  8.4183e-02,  3.8204e+00,  ...,  1.5708e+00,\n",
      "           1.5698e+00,  3.8560e+00],\n",
      "         [ 5.3327e-01,  3.7502e-01,  3.7314e+00,  ...,  1.5709e+00,\n",
      "           1.5706e+00,  3.7879e+00],\n",
      "         [ 5.4724e-01,  6.6174e-01,  3.6289e+00,  ...,  1.5709e+00,\n",
      "           1.5708e+00,  3.7291e+00],\n",
      "         ...,\n",
      "         [ 4.1109e-01,  5.8755e-01,  3.4117e+00,  ...,  1.5715e+00,\n",
      "           1.5307e+00,  3.4862e+00],\n",
      "         [ 2.1822e-01,  6.7483e-01,  3.5793e+00,  ...,  1.5752e+00,\n",
      "           1.5772e+00,  3.6489e+00],\n",
      "         [ 2.3204e-01,  6.1742e-01,  3.5249e+00,  ...,  1.5737e+00,\n",
      "           1.5723e+00,  3.5860e+00]],\n",
      "\n",
      "        [[ 5.1581e-01,  8.6021e-02,  3.8187e+00,  ...,  1.5708e+00,\n",
      "           1.5703e+00,  3.8543e+00],\n",
      "         [ 5.3312e-01,  3.7618e-01,  3.7311e+00,  ...,  1.5708e+00,\n",
      "           1.5705e+00,  3.7877e+00],\n",
      "         [ 5.4718e-01,  6.6239e-01,  3.6296e+00,  ...,  1.5708e+00,\n",
      "           1.5706e+00,  3.7299e+00],\n",
      "         ...,\n",
      "         [ 4.0413e-01,  5.7716e-01,  3.4050e+00,  ...,  1.5728e+00,\n",
      "           1.5738e+00,  3.4771e+00],\n",
      "         [ 2.0383e-01,  6.5569e-01,  3.5872e+00,  ...,  1.5747e+00,\n",
      "           1.5760e+00,  3.6523e+00],\n",
      "         [ 2.0048e-01,  6.1736e-01,  3.5366e+00,  ...,  1.5796e+00,\n",
      "           1.5708e+00,  3.5956e+00]],\n",
      "\n",
      "        [[ 5.1669e-01,  9.4871e-02,  3.8158e+00,  ...,  1.5706e+00,\n",
      "           1.5685e+00,  3.8518e+00],\n",
      "         [ 5.3300e-01,  3.7960e-01,  3.7313e+00,  ...,  1.5708e+00,\n",
      "           1.5699e+00,  3.7882e+00],\n",
      "         [ 5.4676e-01,  6.6316e-01,  3.6319e+00,  ...,  1.5709e+00,\n",
      "           1.5706e+00,  3.7322e+00],\n",
      "         ...,\n",
      "         [ 3.8576e-01,  5.5960e-01,  3.4200e+00,  ...,  1.5761e+00,\n",
      "           1.5758e+00,  3.4869e+00],\n",
      "         [ 1.7720e-01,  6.2882e-01,  3.6102e+00,  ...,  1.5781e+00,\n",
      "           1.5781e+00,  3.6689e+00],\n",
      "         [ 1.8312e-01,  5.7711e-01,  3.5340e+00,  ...,  1.5756e+00,\n",
      "           1.5820e+00,  3.5855e+00]]], device='cuda:0')\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([374, 25, 7])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(4.0859, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([386, 25, 7])\n",
      "tensor(4.0634, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([353, 25, 7])\n",
      "tensor(4.1103, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([486, 25, 7])\n",
      "tensor(4.1143, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([399, 25, 7])\n",
      "tensor([[[ 0.1369, -0.2093,  4.1838,  ...,  1.5708,  1.5708,  4.1912],\n",
      "         [ 0.1404,  0.0435,  4.2062,  ...,  1.5708,  1.5708,  4.2087],\n",
      "         [ 0.1460,  0.2950,  4.2192,  ...,  1.5708,  1.5708,  4.2320],\n",
      "         ...,\n",
      "         [-0.0788, -0.3723,  4.0697,  ...,  1.5708,  1.5708,  4.0874],\n",
      "         [ 0.4338, -0.3719,  4.3485,  ...,  1.5708,  1.5708,  4.3859],\n",
      "         [ 0.4383, -0.3433,  4.3341,  ...,  1.5708,  1.5708,  4.3697]],\n",
      "\n",
      "        [[ 0.5979,  0.0329,  1.2015,  ...,  1.2203,  1.3894,  1.3424],\n",
      "         [ 0.5922,  0.2499,  1.1701,  ...,  1.2256,  1.4155,  1.3350],\n",
      "         [ 0.5805,  0.4524,  1.1256,  ...,  1.2418,  1.4535,  1.3449],\n",
      "         ...,\n",
      "         [ 0.5585,  0.0261,  1.0472,  ...,  1.0041,  1.2286,  1.1871],\n",
      "         [ 0.4432,  0.0122,  1.0777,  ...,  1.5628,  1.2349,  1.1653],\n",
      "         [ 0.4456,  0.0442,  1.0677,  ...,  1.5646,  1.2295,  1.1578]],\n",
      "\n",
      "        [[ 0.1327, -0.2067,  4.1829,  ...,  1.6820,  1.6280,  4.1902],\n",
      "         [ 0.1387,  0.0454,  4.2061,  ...,  1.6788,  1.6194,  4.2086],\n",
      "         [ 0.1454,  0.2960,  4.2193,  ...,  1.6738,  1.6078,  4.2321],\n",
      "         ...,\n",
      "         [-0.0794, -0.3799,  4.0626,  ...,  1.7277,  1.6704,  4.0811],\n",
      "         [ 0.5232, -0.4077,  4.3520,  ...,  1.5526,  1.6663,  4.4023],\n",
      "         [ 0.5279, -0.4068,  4.3420,  ...,  1.5520,  1.6736,  4.3929]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.4083, -0.1007,  2.9524,  ...,  1.5718,  1.5794,  2.9822],\n",
      "         [-0.4035,  0.1449,  2.9061,  ...,  1.5711,  1.5815,  2.9375],\n",
      "         [-0.3970,  0.3871,  2.8487,  ...,  1.5702,  1.5831,  2.9022],\n",
      "         ...,\n",
      "         [-0.5371, -0.1826,  3.1430,  ...,  1.5659,  1.5730,  3.1938],\n",
      "         [-0.2200, -0.2709,  2.7687,  ...,  1.5670,  1.5819,  2.7906],\n",
      "         [-0.1979, -0.2297,  2.7513,  ...,  1.5655,  1.5815,  2.7679]],\n",
      "\n",
      "        [[-0.3968, -0.1238,  2.9332,  ...,  1.5669,  1.5786,  2.9625],\n",
      "         [-0.3980,  0.1321,  2.8884,  ...,  1.5689,  1.5752,  2.9187],\n",
      "         [-0.3959,  0.3809,  2.8326,  ...,  1.5704,  1.5730,  2.8854],\n",
      "         ...,\n",
      "         [-0.5498, -0.2135,  3.1347,  ...,  1.5748,  1.5805,  3.1897],\n",
      "         [-0.2207, -0.3223,  2.7529,  ...,  1.5710,  1.5893,  2.7805],\n",
      "         [-0.1938, -0.2734,  2.7550,  ...,  1.5693,  1.5865,  2.7753]],\n",
      "\n",
      "        [[-0.3947, -0.1325,  2.9458,  ...,  1.5701,  1.5737,  2.9751],\n",
      "         [-0.3940,  0.1219,  2.9001,  ...,  1.5695,  1.5743,  2.9293],\n",
      "         [-0.3912,  0.3706,  2.8439,  ...,  1.5692,  1.5744,  2.8945],\n",
      "         ...,\n",
      "         [-0.5629, -0.1986,  3.1647,  ...,  1.5749,  1.5662,  3.2205],\n",
      "         [-0.2225, -0.3236,  2.7655,  ...,  1.5715,  1.5713,  2.7932],\n",
      "         [-0.2001, -0.2829,  2.7560,  ...,  1.5731,  1.5742,  2.7777]]],\n",
      "       device='cuda:0')\n",
      "tensor(nan, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([545, 25, 7])\n",
      "tensor(3.9485, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([405, 25, 7])\n",
      "tensor(4.0986, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([428, 25, 7])\n",
      "tensor(4.1119, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "torch.Size([280, 25, 7])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-f8f5ace76184>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskeleton_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m#print(output)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/models/net.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, t, adj)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# sequential architecture\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_layers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m                 t = rearrange(fn.relu(self.spatial_layers[i](t, adj)),\n\u001b[0m\u001b[1;32m     48\u001b[0m                               'b n c -> n b c')\n\u001b[1;32m     49\u001b[0m                 t = rearrange(fn.relu(self.temporal_layers[i](t)),\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    720\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    721\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 722\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    723\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    724\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/models/layers.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, adj, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    169\u001b[0m                              \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_alpha_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m                              \u001b[0malpha_\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m                              size=size)\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m         \u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_alpha\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/models/layers.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, adj, size, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 216\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage_and_aggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/models/layers.py\u001b[0m in \u001b[0;36mmessage_and_aggregate\u001b[0;34m(self, adj, x, score)\u001b[0m\n\u001b[1;32m    264\u001b[0m                 \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_attention\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 266\u001b[0;31m         \u001b[0mout_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatched_spmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0madj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mx_r\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/utility/linalg.py\u001b[0m in \u001b[0;36mbatched_spmm\u001b[0;34m(nzt, adj, x, m, n)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnzt_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m  \u001b[0;31m# [batch, heads * num_nodes, channels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/project/gcn/APBGCN/utility/linalg.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0m_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mspmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madj_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnzt_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheads\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m  \u001b[0;31m# [batch, heads * num_nodes, channels]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch_sparse/spmm.py\u001b[0m in \u001b[0;36mspmm\u001b[0;34m(index, value, m, n, matrix)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscatter_add\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for batch_idx, batch in enumerate(train_loader):\n",
    "    batch = batch.to(torch.device('cuda:0'))\n",
    "    target = train_dataset.labels.gather(0, batch.batch)\n",
    "\n",
    "    train_dataset.skeleton_ = train_dataset.skeleton_.to(torch.device('cuda:0'))\n",
    "    print(batch.x.shape)\n",
    "    if torch.isnan(batch.x).any():\n",
    "        print(batch.x)\n",
    "    output = model(batch.x, adj=train_dataset.skeleton_)\n",
    "        \n",
    "    #print(output)\n",
    "    loss = nn.functional.cross_entropy(output, target.long())\n",
    "    print(loss)\n",
    "    pred = torch.max(output, 1)[1]\n",
    "    #print(pred)\n",
    "    results = pred == target\n",
    "    correct_points = torch.sum(results.long())\n",
    "    acc = correct_points.float()/results.size()[0]\n",
    "    #print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
